{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the required header files\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for reading the emails and extracting the message\n",
    "def read_file(path):\n",
    "    \n",
    "    for root, dirname, filenames in os.walk(path):\n",
    "        \n",
    "        for filename in filenames:\n",
    "            \n",
    "            path=os.path.join(root,filename)\n",
    "            f=open(path,'r')\n",
    "            lines=[]\n",
    "            for line in f:\n",
    "                lines.append(line)\n",
    "            f.close()\n",
    "            message='\\n'.join(lines)\n",
    "            yield message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2)\n"
     ]
    }
   ],
   "source": [
    "train_mail=[]\n",
    "\n",
    "# adding spam mails in training dataset\n",
    "for message in read_file('Training_Set/spam'):\n",
    "    train_mail.append([message,'spam'])\n",
    "    \n",
    "# adding ham mails in training dataset\n",
    "for message in read_file('Training_Set/ham'):\n",
    "    train_mail.append([message,'ham'])\n",
    "    \n",
    "# converting train_mail to a numpy array\n",
    "train_data=np.asarray(train_mail)\n",
    "\n",
    "# Shows 700 mails with 2 columns (message,(spam/ham))\n",
    "print (train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_ham={}    # a dictionary for storing count of word given it is ham\n",
    "word_count_spam={}   # a dictionary for storing count of word given it is spam\n",
    "word_ignore=[]       # stores useless words, so that we can ignore them in future\n",
    "spam_num=0           # number of spam mails\n",
    "ham_num=0            # number of ham mails\n",
    "\n",
    "# iterating all mails\n",
    "for j in range(train_data.shape[0]):\n",
    "    \n",
    "    # storing words from message body\n",
    "    words = train_data[j][0].split(' ')\n",
    "    \n",
    "    #counting no. of spam/ham mails\n",
    "    if train_data[j][1]=='spam':\n",
    "        spam_num+=1\n",
    "    else:\n",
    "        ham_num+=1\n",
    "    \n",
    "    # iterating all words in that mail\n",
    "    for i in words:\n",
    "        \n",
    "        #storing useless words\n",
    "        if len(i)<2:\n",
    "            if not i in word_ignore:\n",
    "                word_ignore.append(i)\n",
    "            continue\n",
    "        \n",
    "        # calculating word count given its a spam\n",
    "        if train_data[j][1]=='spam':\n",
    "            if i in word_count_spam:\n",
    "                word_count_spam[i]+=1\n",
    "            else:\n",
    "                word_count_spam[i]=1\n",
    "        # calculating word count given its a ham\n",
    "        else:\n",
    "            if i in word_count_ham:\n",
    "                word_count_ham[i]+=1\n",
    "            else:\n",
    "                word_count_ham[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#probability of a mail being a spam\n",
    "spam_prob=(float(spam_num))/(float(spam_num+ham_num))\n",
    "#probability of a mail being a ham\n",
    "ham_prob=(1.0-spam_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 2)\n"
     ]
    }
   ],
   "source": [
    "test_mail=[]\n",
    "\n",
    "# adding spam mails in testing dataset\n",
    "for message in read_file('Testing_Set/spam'):\n",
    "    test_mail.append([message,'spam'])\n",
    "    \n",
    "# adding ham mails in testing dataset\n",
    "for message in read_file('Testing_Set/ham'):\n",
    "    test_mail.append([message,'ham'])\n",
    "    \n",
    "# converting test_mail to a numpy array\n",
    "test_data=np.asarray(test_mail)\n",
    "\n",
    "# Shows 260 mails with 2 columns (message,(spam/ham))\n",
    "print (test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list to store predicted labels\n",
    "test_predict=[]\n",
    "\n",
    "# iterating all testing mails\n",
    "for j in range(test_data.shape[0]):\n",
    "    \n",
    "    # storing words from message body\n",
    "    words = test_data[j][0].split(' ')\n",
    "    \n",
    "    # used to predict whether than word appears more often in spam or ham\n",
    "    ham_contribution=0\n",
    "    spam_contribution=0\n",
    "    \n",
    "    for i in words:\n",
    "        \n",
    "        # ignore the useless words and the unknown words\n",
    "        if i in word_ignore or i not in word_count_spam or i not in word_count_ham:\n",
    "            continue\n",
    "            \n",
    "        # if word is not spam, its definitely a ham (since unknown words have been taken care of above)    \n",
    "        if i not in word_count_spam:\n",
    "            ham_contribution+=1.0\n",
    "            continue\n",
    "            \n",
    "        # if word is not ham, its definitely a spam\n",
    "        if i not in word_count_ham:\n",
    "            spam_contribution+=1.0\n",
    "            continue\n",
    "        \n",
    "        # using bayes theorem to calculate the probabilities for spam/ham\n",
    "        p1=spam_prob*word_count_spam[i]/(word_count_ham[i]+word_count_spam[i])\n",
    "        p2=ham_prob*word_count_ham[i]/(word_count_ham[i]+word_count_spam[i])\n",
    "        \n",
    "        # Calculating the contribution of each word being a spam or a ham\n",
    "        spam_contribution+=p1\n",
    "        ham_contribution+=p2   \n",
    "    \n",
    "    # predicting labels\n",
    "    if spam_contribution>ham_contribution:\n",
    "        test_predict.append('spam')\n",
    "    else:\n",
    "        test_predict.append('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  92.3076923076923\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy of predicted labels by comparing with actual labels\n",
    "x=0\n",
    "for i in range(test_data.shape[0]):\n",
    "    if test_predict[i]==test_data[i][1]:\n",
    "        x+=1\n",
    "print (\"Accuracy: \", 100*x/test_data.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
